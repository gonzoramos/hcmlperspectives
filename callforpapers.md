---
sidebar:
  - title: "Important Dates:"
    image_alt: "A human at the center of something, something, machine learning."
    text: "Papers Deadline: 12-Feb-2019"
  - extra: ""
    text: "Papers Decisions: 1-Mar-2019"
  - extra: ""
    text: "Workshop: 4-May-2019"
    
layout: single
title: Call for Papers!
---

Machine Learning (ML) is currently one of the most important technologies used across systems affecting research, commerce, healthcare, entertainment, security, etc.
As its use grows, woven into our society and affecting the lives of people, it has become important to study and design the interactions between ML and its stakeholders from a Human-Centered point of view. Human-Centered Machine Learning (HCML) shares this view and re-frames work on and related to ML in term of human goals.
This workshop picks up from a [prior workshop](http://hcml2016.goldsmithsdigital.com/){:target="\_blank"} that took place at CHI 2016 and invites ideas focusing on (but not limited to) the themes of lowering the barrier of entry to ML, teaching to machines with richer knowledge than just labels, and explainable decisions and ML systems *from a Human-Centered point of view*
. For example:

- What are the foreseeable positive and negative consequences of democratizing ML? How should we prepare and respond to them?
- How much should we allow a person to know about the underlying learning algorithm in an end-user ML, or machine teaching system?
- What are the different ways to express and leverage human knowledge beyond labels? e.g., features, schema, concept decomposition, samples, etc.
- How can we help a person map/decompose a problem to an ML-driven solution?
- What is a sufficient (and ML agnostic) teaching language for different domains such as text, or images?
- What are the many definitions for explanations and intelligibility?
- What are proper metrics to measure explainability and intelligibility?
- What are the different ways to explain an algorithmic decision?
- Models created through machine teaching are semantic; i.e., the decisions made by these models are explainable in human terms. Are these explanations sufficient under the many different definitions and contexts of explainability?
- When are explanations necessary, or aren't?
- What is the cost of maintaining, debugging, sharing an end-user ML solution?

By articulating these emerging perspectives, we look at how, as a community, we keep moving the HCML field forward.

## How to Participate
We invite the submission of positions papers between 3-6 pages long. Position papers should follow the CHI Extended Abstract [format](http://chi2019.acm.org/authors/chi-proceedings-format/){:target="_blank"} and be submitted through our [CMT submission site](https://cmt3.research.microsoft.com/HCMLP2019){:target="_blank"}.

The workshop`s organizing committee will review the submissions and accepted papers will be presented at the workshop. We ask that at least one of the authors of each accepted position paper attends the workshop. Presenting authors must register for the workshop and at least one full day of the conference.

Each presentation will take place within a session focused around a particular theme. Sessions will consist of 3-4 presentations, each lasting approximately 10 minutes and will be followed by a group discussion.

## Contact Us
For any additional questions, please contact us at [goramos@microsoft.com](mailto:goramos@microsoft.com){:target="_blank"}
